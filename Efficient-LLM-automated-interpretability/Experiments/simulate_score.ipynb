{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils\n",
    "from neuron_explainer.activations.activations import load_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>neuron</th>\n",
       "      <th>explainer</th>\n",
       "      <th>NeuronViewer</th>\n",
       "      <th>Original</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Highlight</th>\n",
       "      <th>HighlightSummary</th>\n",
       "      <th>AVHS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>words related to comparison.</td>\n",
       "      <td>comparisons and relative differences.</td>\n",
       "      <td>words that indicate a comparison or a contrast.</td>\n",
       "      <td>words that can be paired with \"compar\".</td>\n",
       "      <td>words that indicate similarity or contrast.</td>\n",
       "      <td>words that mean 'different' or 'similar' when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1838</td>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>phrases describing positions or situations in...</td>\n",
       "      <td>individuals or groups who find themselves in s...</td>\n",
       "      <td>words or phrases that convey a sense of someth...</td>\n",
       "      <td>third person singular present tense verb forms...</td>\n",
       "      <td>first/second/third person reflexive forms of t...</td>\n",
       "      <td>the token \"in\" together with other words that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>193</td>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>verbs indicating questioning or challenging be...</td>\n",
       "      <td>phrases related to social criticism and accoun...</td>\n",
       "      <td>phrases related to criticism, condemnation, or...</td>\n",
       "      <td>words related to social hierarchy and inequali...</td>\n",
       "      <td>words related to criticism, confrontation, and...</td>\n",
       "      <td>words related to negative actions or behaviors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>1685</td>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>expressions of gratitude and agreeing to rece...</td>\n",
       "      <td>opt-in forms for email newsletters and such re...</td>\n",
       "      <td>phrases related to subscriptions, permission t...</td>\n",
       "      <td>text segments related to newsletters, subscrip...</td>\n",
       "      <td>phrases related to user agreements, permission...</td>\n",
       "      <td>phrases related to taking or being a step.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>431</td>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>numbers related to time, dates, and measureme...</td>\n",
       "      <td>data about upcoming events, specifically sport...</td>\n",
       "      <td>numbers, especially times and dates in the for...</td>\n",
       "      <td>time-related expressions and numerical values.</td>\n",
       "      <td>colons and numerals.</td>\n",
       "      <td>time-related information, specifically items r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer  neuron                   explainer  \\\n",
       "0      0     286  Meta-Llama-3.1-8B-Instruct   \n",
       "1     10    1838  Meta-Llama-3.1-8B-Instruct   \n",
       "2     20     193  Meta-Llama-3.1-8B-Instruct   \n",
       "3     30    1685  Meta-Llama-3.1-8B-Instruct   \n",
       "4     40     431  Meta-Llama-3.1-8B-Instruct   \n",
       "\n",
       "                                        NeuronViewer  \\\n",
       "0                       words related to comparison.   \n",
       "1   phrases describing positions or situations in...   \n",
       "2  verbs indicating questioning or challenging be...   \n",
       "3   expressions of gratitude and agreeing to rece...   \n",
       "4   numbers related to time, dates, and measureme...   \n",
       "\n",
       "                                            Original  \\\n",
       "0              comparisons and relative differences.   \n",
       "1  individuals or groups who find themselves in s...   \n",
       "2  phrases related to social criticism and accoun...   \n",
       "3  opt-in forms for email newsletters and such re...   \n",
       "4  data about upcoming events, specifically sport...   \n",
       "\n",
       "                                             Summary  \\\n",
       "0    words that indicate a comparison or a contrast.   \n",
       "1  words or phrases that convey a sense of someth...   \n",
       "2  phrases related to criticism, condemnation, or...   \n",
       "3  phrases related to subscriptions, permission t...   \n",
       "4  numbers, especially times and dates in the for...   \n",
       "\n",
       "                                           Highlight  \\\n",
       "0            words that can be paired with \"compar\".   \n",
       "1  third person singular present tense verb forms...   \n",
       "2  words related to social hierarchy and inequali...   \n",
       "3  text segments related to newsletters, subscrip...   \n",
       "4     time-related expressions and numerical values.   \n",
       "\n",
       "                                    HighlightSummary  \\\n",
       "0        words that indicate similarity or contrast.   \n",
       "1  first/second/third person reflexive forms of t...   \n",
       "2  words related to criticism, confrontation, and...   \n",
       "3  phrases related to user agreements, permission...   \n",
       "4                               colons and numerals.   \n",
       "\n",
       "                                                AVHS  \n",
       "0  words that mean 'different' or 'similar' when ...  \n",
       "1  the token \"in\" together with other words that ...  \n",
       "2  words related to negative actions or behaviors...  \n",
       "3         phrases related to taking or being a step.  \n",
       "4  time-related information, specifically items r...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIMULATOR_MODEL = \"Meta-Llama-3.1-8B-Instruct\"#\"gpt-3.5-turbo-instruct\"\n",
    "INPUT_PATH = \"test_results/test_neurons_results.csv\"\n",
    "\n",
    "neuron_results_df = pd.read_csv(INPUT_PATH).drop('Unnamed: 0', axis = 1)\n",
    "neuron_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     simScore_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneuron\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(neuron)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m modes:\n\u001b[0;32m---> 13\u001b[0m         simScore_results[mode]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mawait\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mget_score( row[mode], layer, neuron, SIMULATOR_MODEL))\n\u001b[1;32m     15\u001b[0m new_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(simScore_results)\n\u001b[1;32m     16\u001b[0m new_df\n",
      "File \u001b[0;32m/workspace/Efficient-LLM-automated-interpretability/neuron-explainer/utils.py:206\u001b[0m, in \u001b[0;36mget_score\u001b[0;34m(explanation, layer, neuron, simulator_model)\u001b[0m\n\u001b[1;32m    194\u001b[0m valid_activation_records \u001b[38;5;241m=\u001b[39m neuron_record\u001b[38;5;241m.\u001b[39mvalid_activation_records(\n\u001b[1;32m    195\u001b[0m     activation_record_slice_params\u001b[38;5;241m=\u001b[39mslice_params\n\u001b[1;32m    196\u001b[0m )\n\u001b[1;32m    198\u001b[0m simulator \u001b[38;5;241m=\u001b[39m UncalibratedNeuronSimulator(\n\u001b[1;32m    199\u001b[0m     ExplanationNeuronSimulator(\n\u001b[1;32m    200\u001b[0m         SIMULATOR_MODEL_NAME,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    205\u001b[0m )\n\u001b[0;32m--> 206\u001b[0m scored_simulation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m simulate_and_score(simulator, valid_activation_records)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscored_simulation\u001b[38;5;241m.\u001b[39mget_preferred_score()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspace/Efficient-LLM-automated-interpretability/neuron-explainer/neuron_explainer/explanations/scoring.py:137\u001b[0m, in \u001b[0;36msimulate_and_score\u001b[0;34m(simulator, activation_records)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimulate_and_score\u001b[39m(\n\u001b[1;32m    130\u001b[0m     simulator: NeuronSimulator,\n\u001b[1;32m    131\u001b[0m     activation_records: Sequence[ActivationRecord],\n\u001b[1;32m    132\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ScoredSimulation:\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    Score an explanation of a neuron by how well it predicts activations on the given text\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    sequences.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     scored_sequence_simulations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;241m*\u001b[39m[\n\u001b[1;32m    139\u001b[0m             _simulate_and_score_sequence(\n\u001b[1;32m    140\u001b[0m                 simulator,\n\u001b[1;32m    141\u001b[0m                 activation_record,\n\u001b[1;32m    142\u001b[0m             )\n\u001b[1;32m    143\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m activation_record \u001b[38;5;129;01min\u001b[39;00m activation_records\n\u001b[1;32m    144\u001b[0m         ]\n\u001b[1;32m    145\u001b[0m     )\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m aggregate_scored_sequence_simulations(scored_sequence_simulations)\n",
      "File \u001b[0;32m/workspace/Efficient-LLM-automated-interpretability/neuron-explainer/neuron_explainer/explanations/scoring.py:82\u001b[0m, in \u001b[0;36m_simulate_and_score_sequence\u001b[0;34m(simulator, activations)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_simulate_and_score_sequence\u001b[39m(\n\u001b[1;32m     79\u001b[0m     simulator: NeuronSimulator, activations: ActivationRecord\n\u001b[1;32m     80\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ScoredSequenceSimulation:\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Score an explanation of a neuron by how well it predicts activations on a sentence.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     simulation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m simulator\u001b[38;5;241m.\u001b[39msimulate(activations\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[1;32m     83\u001b[0m     logging\u001b[38;5;241m.\u001b[39mdebug(simulation)\n\u001b[1;32m     84\u001b[0m     rsquared_score \u001b[38;5;241m=\u001b[39m score_from_simulation(activations, simulation, rsquared_score_from_sequences)\n",
      "File \u001b[0;32m/workspace/Efficient-LLM-automated-interpretability/neuron-explainer/neuron_explainer/explanations/calibrated_simulator.py:102\u001b[0m, in \u001b[0;36mCalibratedNeuronSimulator.simulate\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimulate\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens: Sequence[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SequenceSimulation:\n\u001b[0;32m--> 102\u001b[0m     uncalibrated_seq_simulation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncalibrated_simulator\u001b[38;5;241m.\u001b[39msimulate(tokens)\n\u001b[1;32m    103\u001b[0m     calibrated_activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_calibration(\n\u001b[1;32m    104\u001b[0m         uncalibrated_seq_simulation\u001b[38;5;241m.\u001b[39mexpected_activations\n\u001b[1;32m    105\u001b[0m     )\n\u001b[1;32m    106\u001b[0m     calibrated_distribution_values \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_calibration(dv) \u001b[38;5;28;01mfor\u001b[39;00m dv \u001b[38;5;129;01min\u001b[39;00m uncalibrated_seq_simulation\u001b[38;5;241m.\u001b[39mdistribution_values\n\u001b[1;32m    108\u001b[0m     ]\n",
      "File \u001b[0;32m/workspace/Efficient-LLM-automated-interpretability/neuron-explainer/neuron_explainer/explanations/simulator.py:344\u001b[0m, in \u001b[0;36mExplanationNeuronSimulator.simulate\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    342\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m prompt\n\u001b[0;32m--> 344\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mmake_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[1;32m    345\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse in score_explanation_by_activations is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response)\n\u001b[1;32m    346\u001b[0m result \u001b[38;5;241m=\u001b[39m parse_simulation_response(response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_format, tokens)\n",
      "File \u001b[0;32m/workspace/Efficient-LLM-automated-interpretability/neuron-explainer/neuron_explainer/api_client.py:72\u001b[0m, in \u001b[0;36mexponential_backoff.<locals>.decorate.<locals>.f_retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mretry_on\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m==\u001b[39m max_tries \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     jittered_delay \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39muniform(delay_s \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m jitter), delay_s \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m jitter))\n",
      "File \u001b[0;32m/workspace/Efficient-LLM-automated-interpretability/neuron-explainer/neuron_explainer/api_client.py:17\u001b[0m, in \u001b[0;36mis_api_error\u001b[0;34m(err)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError):\n\u001b[1;32m     16\u001b[0m     response \u001b[38;5;241m=\u001b[39m err\u001b[38;5;241m.\u001b[39mresponse\n\u001b[0;32m---> 17\u001b[0m     error_data \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m     18\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m error_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m404\u001b[39m, \u001b[38;5;241m415\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/sae/lib/python3.10/site-packages/httpx/_models.py:832\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjson\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjsonlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sae/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/envs/sae/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/miniconda3/envs/sae/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "modes = [\"Original\", \"Summary\", \"Highlight\", \"HighlightSummary\", \"AVHS\"]\n",
    "simScore_results = {\"layer\":[], \"neuron\":[]}\n",
    "for mode in modes:\n",
    "    simScore_results[mode] = []\n",
    "\n",
    "for i, row in neuron_results_df.iterrows():\n",
    "    layer = row[\"layer\"]\n",
    "    neuron = row[\"neuron\"]\n",
    "    simScore_results[\"layer\"].append(layer)\n",
    "    simScore_results[\"neuron\"].append(neuron)\n",
    "    \n",
    "    for mode in modes:\n",
    "        simScore_results[mode].append(await utils.get_score( row[mode], layer, neuron, SIMULATOR_MODEL))\n",
    "\n",
    "new_df = pd.DataFrame(simScore_results)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(INPUT_PATH.split(\".\")[0] + \"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = {'max_tokens': 0, 'echo': True, 'logprobs': 15, 'prompt': 'We\\'re studying neurons in a neural network.\\nEach neuron looks for some particular thing in a short document.\\nLook at summary of what the neuron does, and try to predict how it will fire on each token.\\n\\nThe activation format is token<tab>activation, activations go from 0 to 10, \"unknown\" indicates an unknown activation. Most activations will be 0.\\n\\n\\nNeuron 1\\nExplanation of neuron 1 behavior: the main thing this neuron does is find present tense verbs ending in \\'ing\\'\\nActivations: \\n<start>\\nt\\tunknown\\nurt\\tunknown\\nur\\tunknown\\nro\\tunknown\\n is\\tunknown\\n fab\\tunknown\\nulously\\tunknown\\n funny\\tunknown\\n and\\tunknown\\n over\\tunknown\\n the\\t0\\n top\\t0\\n as\\t0\\n a\\t0\\n \\'\\t0\\nvery\\t0\\n sneaky\\t0\\n\\'\\t1\\n but\\t0\\nler\\t0\\n who\\t0\\n excel\\t0\\ns\\t0\\n in\\t0\\n the\\t0\\n art\\t0\\n of\\t0\\n impossible\\t0\\n disappearing\\t6\\n/\\t0\\nre\\t0\\napp\\t0\\nearing\\t10\\n acts\\t0\\n<end>\\n<start>\\nesc\\tunknown\\naping\\tunknown\\n the\\tunknown\\n studio\\t0\\n ,\\t0\\n pic\\t0\\ncol\\t0\\ni\\t0\\n is\\t0\\n warm\\t0\\nly\\t0\\n affecting\\t3\\n and\\t0\\n so\\t0\\n is\\t0\\n this\\t0\\n ad\\t0\\nroit\\t0\\nly\\t0\\n minimalist\\t0\\n movie\\t0\\n .\\t0\\n<end>\\n\\n\\n\\nNeuron 2\\nExplanation of neuron 2 behavior: the main thing this neuron does is find words related to physical medical conditions\\nActivations: \\n<start>\\nas\\tunknown\\n sac\\tunknown\\nchar\\tunknown\\nine\\tunknown\\n movies\\tunknown\\n go\\t0\\n ,\\t0\\n this\\t0\\n is\\t0\\n likely\\t0\\n to\\t0\\n cause\\t0\\n massive\\t0\\n cardiac\\t0\\n arrest\\t10\\n if\\t0\\n taken\\t0\\n in\\t0\\n large\\t0\\n doses\\t0\\n .\\t0\\n<end>\\n<start>\\nshot\\tunknown\\n perhaps\\tunknown\\n \\'\\tunknown\\nart\\tunknown\\nistically\\tunknown\\n\\'\\tunknown\\n with\\tunknown\\n handheld\\tunknown\\n cameras\\tunknown\\n and\\tunknown\\n apparently\\tunknown\\n no\\tunknown\\n movie\\tunknown\\n lights\\tunknown\\n by\\tunknown\\n jo\\tunknown\\naquin\\tunknown\\n b\\tunknown\\naca\\tunknown\\n-\\tunknown\\nas\\t0\\nay\\t0\\n ,\\t0\\n the\\t0\\n low\\t0\\n-\\t0\\nbudget\\t0\\n production\\t0\\n swings\\t0\\n annoy\\t0\\ningly\\t0\\n between\\t0\\n vert\\t0\\nigo\\t9\\n and\\t0\\n opacity\\t0\\n .\\t0\\n<end>\\n\\n\\n\\nNeuron 3\\nExplanation of neuron 3 behavior: the main thing this neuron does is find phrases related to community\\nActivations: \\n<start>\\nthe\\t0\\n sense\\t0\\n of\\t0\\n together\\t3\\nness\\t7\\n in\\t0\\n our\\t0\\n town\\t1\\n is\\t0\\n strong\\t0\\n .\\t0\\n<end>\\n<start>\\na\\tunknown\\n buoy\\tunknown\\nant\\tunknown\\n romantic\\tunknown\\n comedy\\tunknown\\n about\\tunknown\\n friendship\\tunknown\\n ,\\tunknown\\n love\\tunknown\\n ,\\tunknown\\n and\\t0\\n the\\t0\\n truth\\t0\\n that\\t0\\n we\\t2\\n\\'re\\t4\\n all\\t3\\n in\\t7\\n this\\t10\\n together\\t5\\n .\\t0\\n<end>\\n\\n\\n\\nNeuron 4\\nExplanation of neuron 4 behavior: the main thing this neuron does is find comparisons and relative differences.<|endofprompt|>\\nActivations: \\n<start>\\n covered\\tunknown\\n under\\tunknown\\n another\\tunknown\\n contract\\tunknown\\n with\\tunknown\\n Pratt\\tunknown\\n &\\tunknown\\n Whitney\\tunknown\\n,\\tunknown\\n a\\tunknown\\n United\\tunknown\\n Technologies\\tunknown\\n UT\\tunknown\\nX\\tunknown\\n unit\\tunknown\\n.\\tunknown\\n\\n\\n\\tunknown\\n\\n\\tunknown\\nCompared\\tunknown\\n to\\tunknown\\n the\\tunknown\\n lot\\tunknown\\n 9\\tunknown\\n production\\tunknown\\n,\\tunknown\\n lot\\tunknown\\n 10\\tunknown\\n represents\\tunknown\\n a\\tunknown\\n reduction\\tunknown\\n of\\tunknown\\n $\\tunknown\\n728\\tunknown\\n million\\tunknown\\n in\\tunknown\\n costs\\tunknown\\n.\\tunknown\\n\\n\\n\\tunknown\\n\\n\\tunknown\\nAccording\\tunknown\\n to\\tunknown\\n Lockheed\\tunknown\\n Martin\\tunknown\\n,\\tunknown\\n \"\\tunknown\\nthe\\tunknown\\n increase\\tunknown\\n in\\tunknown\\n the\\tunknown\\n number\\tunknown\\n of\\tunknown\\n aircraft\\tunknown\\n in\\tunknown\\n this\\tunknown\\n agreement\\tunknown\\n enables\\tunknown\\n us\\tunknown\\n to\\tunknown\\n reduce\\tunknown\\n costs\\tunknown\\n by\\tunknown\\n taking\\tunknown\\n advantage\\tunknown\\n of\\tunknown\\n<end>\\n', 'model': 'Meta-Llama-3.1-8B-Instruct'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['max_tokens', 'echo', 'logprobs', 'prompt', 'model'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae",
   "language": "python",
   "name": "sae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
